{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initializing\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_gbq as pgbq\n",
    "from multiprocessing import Pool\n",
    "from scipy import stats\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "from get_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "google_project_id = 'solid-ridge-104914'\n",
    "dataset = 'community_networks'\n",
    "sql_module_types = ['community_facts','transaction','follow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_table(module_type):\n",
    "    print(module_type)\n",
    "    if __name__ == '__main__':\n",
    "        with Pool(processes=len(sql_modules)) as pool:\n",
    "            result = pool.map(bigquery_worker, (range(len(sql_modules),)))\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "    joined = result[0].set_index('cid', drop=True)\n",
    "    print('Joining ',module_type,' modules', sep='')\n",
    "    for i in range(len(result)-1):\n",
    "        joined = joined.join(result[i+1].set_index('cid'), how='left', lsuffix='_left')\n",
    "    table = joined.replace([np.inf,-np.inf], np.nan)\n",
    "    table.fillna(0, inplace=True)\n",
    "    table.sort_index(inplace=True)\n",
    "    if re.match('community_facts', module_type) is None:\n",
    "        table = add_network_stats(table, module_type)\n",
    "    #pgbq.to_gbq(network_stats, dataset+'.'+sql_module_type+'_stats', google_project_id, if_exists='replace', verbose=False)\n",
    "    print('Done', sep='')\n",
    "    return(table)\n",
    "\n",
    "def open_active_modules(module_type):\n",
    "    directory = '/Users/joshharris/community_health/sql/module_types/'+module_type\n",
    "    sql_files = list(map(lambda x: os.path.splitext(x), os.listdir(directory)))\n",
    "    sql_modules = list()\n",
    "    for i in range(len(sql_files)):\n",
    "        if sql_files[i][1] == '.on':\n",
    "            sql_modules.append(sql_files[i][0])\n",
    "    return(sql_modules)\n",
    "\n",
    "def bigquery_worker(i):\n",
    "    sql_module = sql_modules[i]\n",
    "    print('Starting module ',i,': ',sql_modules[i], sep='')\n",
    "    try:\n",
    "        result = pgbq.read_gbq('select * from community_networks.'+module_type+'_'+sql_module, google_project_id, dialect='standard', verbose=False)\n",
    "        print(module_type,'_',sql_module,' table found.', sep='')\n",
    "    except:\n",
    "        print(module_type,'_',sql_module,' table does not exist, generating now', sep='')\n",
    "        with open(directory+'/'+sql_module) as query_file:\n",
    "            query = query_file.read()\n",
    "        result = pgbq.read_gbq(query, google_project_id, dialect='standard', verbose=False)\n",
    "        print('Creating new ',module_type,'_',sql_module,' table', sep='')\n",
    "        pgbq.to_gbq(result, dataset+'.'+module_type+'_'+sql_module, google_project_id, if_exists='replace', verbose=False)\n",
    "        print('Module ',i,': ',sql_module,'query complete', sep='')\n",
    "    return (result)\n",
    "\n",
    "def add_network_stats(df, sql_module_type):\n",
    "    edges = df[sql_module_type+'_edges']\n",
    "    nodes = df[sql_module_type+'_nodes']\n",
    "    avg_indegree = df[sql_module_type+'_avg_indegree']\n",
    "    avg_outdegree = df[sql_module_type+'_avg_outdegree']\n",
    "    df[sql_module_type+'_network_density_X_100'] = (edges/(nodes*(nodes-1)/2))*100\n",
    "    df[sql_module_type+'_indegree_skew'] = (avg_indegree-avg_outdegree)/avg_outdegree\n",
    "    df.drop([sql_module_type+'_edges',sql_module_type+'_nodes'], axis=1, inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "community_facts\n",
      "Starting module 1: communities_per_user\n",
      "Starting module 0: _community_age\n",
      "Starting module 3: items_posted\n",
      "Starting module 6: pct_with_about_me\n",
      "Starting module 2: distance_from_center\n",
      "Starting module 4: m3_total_retention\n",
      "Starting module 5: pct_female_mau\n",
      "community_facts__community_age table found.\n",
      "community_facts_m3_total_retention table found.\n",
      "community_facts_pct_with_about_me table found.\n",
      "community_facts_items_posted table found.\n",
      "community_facts_pct_female_mau table found.\n",
      "community_facts_distance_from_center table found.\n",
      "community_facts_communities_per_user table found.\n",
      "Joining community_facts modules\n",
      "Done\n",
      "transaction\n",
      "Starting module 0: edge_weight\n",
      "Starting module 1: edges\n",
      "Starting module 2: indegree\n",
      "Starting module 4: outdegree\n",
      "Starting module 3: nodes\n",
      "transaction_nodes table found.\n",
      "transaction_indegree table found.\n",
      "transaction_outdegree table found.\n",
      "transaction_edges table found.\n",
      "transaction_edge_weight table found.\n",
      "Joining transaction modules\n",
      "Done\n",
      "follow\n",
      "Starting module 0: edges\n",
      "Starting module 1: indegree\n",
      "Starting module 3: outdegree\n",
      "Starting module 2: nodes\n",
      "follow_outdegree table found.\n",
      "follow_edges table found.\n",
      "follow_indegree table found.\n",
      "follow_nodes table found.\n",
      "Joining follow modules\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "data = pgbq.read_gbq('select id cid from vs_reporting.communities', google_project_id, dialect='standard', verbose=False).set_index('cid', drop=False)\n",
    "\n",
    "for module_type in sql_module_types:\n",
    "    sql_modules = open_active_modules(module_type)\n",
    "    module_table = build_table(module_type)\n",
    "    data = data.join(module_table, how='left', lsuffix='_left')\n",
    "\n",
    "feature_set = data.replace([np.inf,-np.inf], np.nan)\n",
    "feature_set.fillna(0, inplace=True)\n",
    "feature_set = feature_set.iloc[:,2:]\n",
    "feature_set.drop(feature_set[feature_set.avg_communities_per_user == 0].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross correlate community facts and output key correlations\n",
    "\n",
    "variables = list(feature_set)[:len(feature_set)] #this is not a good way to create the list of variables.. why not\n",
    "print(variables)\n",
    "corr_matrix = pd.DataFrame(index=variables, columns=variables)\n",
    "key_correlations = pd.DataFrame(columns=['pair','coefficient'])\n",
    "corr_checked = list()\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for i in range(len(variables)):\n",
    "    for j in range(len(variables)):\n",
    "        pair = variables[i]+','+variables[j]\n",
    "        rho, pval = stats.spearmanr(feature_set[[variables[i],variables[j]]])\n",
    "        corr_matrix.set_value(variables[i], variables[j], rho)\n",
    "        if pair not in corr_checked and rho < 0.99 and (rho > 0.4 or rho < -0.4):\n",
    "            key_correlations.loc[len(key_correlations)] = [pair, rho]\n",
    "            corr_checked.append(variables[j]+','+variables[i]) \n",
    "            \n",
    "\n",
    "corr_matrix.reset_index(inplace=True)\n",
    "key_correlations.sort_values(by='coefficient', ascending=False, inplace=True)\n",
    "key_correlations.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Save to BigQuery\n",
    "#pgbq.to_gbq(transaction_corr_matrix, 'community_networks.transaction_corr_matrix_over_1000', google_project_id, if_exists='replace')\n",
    "#pgbq.to_gbq(transaction_key_correlations, 'community_networks.transaction_key_correlations_over_1000', google_project_id, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "pct_with_about_me correlates with pct_female_mau\n",
    " - action: encourage men to fill in their about me\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.switch_backend('MacOSX') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop = pd.concat([pd.DataFrame(feature_set.iloc[:,3:])], axis = 1, join_axes = [feature_set.index])\n",
    "data = pd.DataFrame(scale(drop))\n",
    "data3D = pd.DataFrame(PCA(n_components=3).fit_transform(data)) # Reduce dimensions from 4 to 3 for visualization\n",
    "data2D = pd.DataFrame(PCA(n_components=2).fit_transform(data)) # Reduce dimensions from 4 to 2 for visualization\n",
    "\n",
    "# run kmeans with 10 sets of clusters seeds\n",
    "# extract classification labels and cluster centers \n",
    "# do some prep for vizualization\n",
    "def cluster_it_up(N):\n",
    "    kmeans = KMeans(init = 'k-means++', n_clusters = N, n_init = 100).fit(drop) # it's as easy as a function call\n",
    "    labels = pd.DataFrame((kmeans.labels_)) # extract labels\n",
    "    centers = pd.DataFrame(kmeans.cluster_centers_) # extract centers\n",
    "    centers.columns = drop.columns # give centers table readable column names\n",
    "    labels.columns = ['label'] \n",
    "    clust_out = pd.concat([feature_set, labels], axis=1, join_axes = [feature_set.index]) # make DataFrame that is labeled users and their features\n",
    "    viz3D = pd.concat([data3D, labels], axis = 1, join_axes = [data.index]) \n",
    "    viz2D = pd.concat([data2D, labels], axis = 1, join_axes = [data2D.index])\n",
    "    return clust_out, centers, N, feature_set, data, labels, viz3D, viz2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clust_out, centers, N, strip, data, labels, viz3D, viz2D  = cluster_it_up(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(centers)))\n",
    "\n",
    "#2D viz\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "for i,c in enumerate(colors):\n",
    "    single_clus = viz2D.loc[viz2D['label'] == i]\n",
    "    plt.scatter(single_clus[0], single_clus[1], s=3, c = c, label=str(i))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#3D viz\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i,c in enumerate(colors):\n",
    "    single_clus = viz3D.loc[viz3D['label'] == i]\n",
    "    ax.scatter(single_clus[1], single_clus[2], single_clus[0], s=20, c = c, label=str(i))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#scatter matrix\n",
    "#scatter_matrix(data, alpha=0.1, figsize=(6, 6), diagonal='kde')\n",
    "#plt.show()\n",
    "\n",
    "centers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
