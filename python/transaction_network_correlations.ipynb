{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The realm of possibility on VarageSale is more like MineCraft than Airbnb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "\n",
    "- adapt sql for other network types\n",
    "- are inweight and outwieght useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge Types\n",
    "\n",
    "- Transaction\n",
    "- Message\n",
    "- Praise\n",
    "- Comment\n",
    "- Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initializing\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_gbq as pgbq\n",
    "from multiprocessing import Pool\n",
    "from scipy import stats\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "from get_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "google_project_id = 'solid-ridge-104914'\n",
    "dataset = 'community_networks'\n",
    "sql_module_types = ['community_facts','transaction','follow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "community_facts\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'result' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2ace69d833a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodule_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msql_module_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msql_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_active_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodule_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshharris/community_health/python/get_features.py\u001b[0m in \u001b[0;36mbuild_table\u001b[0;34m(module_type)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mjoined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Joining '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' modules'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'result' referenced before assignment"
     ]
    }
   ],
   "source": [
    "data = pgbq.read_gbq('select id cid from vs_reporting.communities', google_project_id, dialect='standard', verbose=False).set_index('cid', drop=False)\n",
    "\n",
    "for module_type in sql_module_types:\n",
    "    sql_modules = open_active_modules(module_type)\n",
    "    module_table = build_table(module_type)\n",
    "    data = data.join(module_table, how='left', lsuffix='_left')\n",
    "\n",
    "feature_set = data.replace([np.inf,-np.inf], np.nan)\n",
    "feature_set.fillna(0, inplace=True)\n",
    "feature_set = feature_set.iloc[:,2:]\n",
    "feature_set.drop(feature_set[feature_set.avg_communities_per_user == 0].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def open_active_modules(module_type):\n",
    "    directory = '/Users/joshharris/community_health/sql/module_types/'+module_type\n",
    "    sql_files = list(map(lambda x: os.path.splitext(x), os.listdir(directory)))\n",
    "    sql_modules = list()\n",
    "    for i in range(len(sql_files)):\n",
    "        if sql_files[i][1] == '.on':\n",
    "            sql_modules.append(sql_files[i][0])\n",
    "    return(sql_modules)\n",
    "\n",
    "def bigquery_worker(i):\n",
    "    sql_module = sql_modules[i]\n",
    "    print('Starting module ',i,': ',sql_modules[i], sep='')\n",
    "    try:\n",
    "        result = pgbq.read_gbq('select * from community_networks.'+module_type+'_'+sql_module, google_project_id, dialect='standard', verbose=False)\n",
    "        print(module_type,'_',sql_module,' table found.', sep='')\n",
    "    except:\n",
    "        print(module_type,'_',sql_module,' table does not exist, generating now', sep='')\n",
    "        with open(directory+'/'+sql_module) as query_file:\n",
    "            query = query_file.read()\n",
    "        result = pgbq.read_gbq(query, google_project_id, dialect='standard', verbose=False)\n",
    "        print('Creating new ',module_type,'_',sql_module,' table', sep='')\n",
    "        pgbq.to_gbq(result, dataset+'.'+module_type+'_'+sql_module, google_project_id, if_exists='replace', verbose=False)\n",
    "        print('Module ',i,': ',sql_module,'query complete', sep='')\n",
    "    return (result)\n",
    "\n",
    "def add_network_stats(df, sql_module_type):\n",
    "    edges = df[sql_module_type+'_edges']\n",
    "    nodes = df[sql_module_type+'_nodes']\n",
    "    avg_indegree = df[sql_module_type+'_avg_indegree']\n",
    "    avg_outdegree = df[sql_module_type+'_avg_outdegree']\n",
    "    df[sql_module_type+'_network_density_X_100'] = (edges/(nodes*(nodes-1)/2))*100\n",
    "    df[sql_module_type+'_indegree_skew'] = (avg_indegree-avg_outdegree)/avg_outdegree\n",
    "    df.drop([sql_module_type+'_edges',sql_module_type+'_nodes'], axis=1, inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross correlate community facts and output key correlations\n",
    "\n",
    "variables = list(feature_set)[:len(feature_set)] #this is not a good way to create the list of variables.. why not\n",
    "print(variables)\n",
    "corr_matrix = pd.DataFrame(index=variables, columns=variables)\n",
    "key_correlations = pd.DataFrame(columns=['pair','coefficient'])\n",
    "corr_checked = list()\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for i in range(len(variables)):\n",
    "    for j in range(len(variables)):\n",
    "        pair = variables[i]+','+variables[j]\n",
    "        rho, pval = stats.spearmanr(feature_set[[variables[i],variables[j]]])\n",
    "        corr_matrix.set_value(variables[i], variables[j], rho)\n",
    "        if pair not in corr_checked and rho < 0.99 and (rho > 0.4 or rho < -0.4):\n",
    "            key_correlations.loc[len(key_correlations)] = [pair, rho]\n",
    "            corr_checked.append(variables[j]+','+variables[i]) \n",
    "            \n",
    "\n",
    "corr_matrix.reset_index(inplace=True)\n",
    "key_correlations.sort_values(by='coefficient', ascending=False, inplace=True)\n",
    "key_correlations.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Save to BigQuery\n",
    "#pgbq.to_gbq(transaction_corr_matrix, 'community_networks.transaction_corr_matrix_over_1000', google_project_id, if_exists='replace')\n",
    "#pgbq.to_gbq(transaction_key_correlations, 'community_networks.transaction_key_correlations_over_1000', google_project_id, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "pct_with_about_me correlates with pct_female_mau\n",
    " - action: encourage men to fill in their about me\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.switch_backend('MacOSX') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop = pd.concat([pd.DataFrame(feature_set.iloc[:,3:])], axis = 1, join_axes = [feature_set.index])\n",
    "data = pd.DataFrame(scale(drop))\n",
    "data3D = pd.DataFrame(PCA(n_components=3).fit_transform(data)) # Reduce dimensions from 4 to 3 for visualization\n",
    "data2D = pd.DataFrame(PCA(n_components=2).fit_transform(data)) # Reduce dimensions from 4 to 2 for visualization\n",
    "\n",
    "# run kmeans with 10 sets of clusters seeds\n",
    "# extract classification labels and cluster centers \n",
    "# do some prep for vizualization\n",
    "def cluster_it_up(N):\n",
    "    kmeans = KMeans(init = 'k-means++', n_clusters = N, n_init = 100).fit(drop) # it's as easy as a function call\n",
    "    labels = pd.DataFrame((kmeans.labels_)) # extract labels\n",
    "    centers = pd.DataFrame(kmeans.cluster_centers_) # extract centers\n",
    "    centers.columns = drop.columns # give centers table readable column names\n",
    "    labels.columns = ['label'] \n",
    "    clust_out = pd.concat([feature_set, labels], axis=1, join_axes = [feature_set.index]) # make DataFrame that is labeled users and their features\n",
    "    viz3D = pd.concat([data3D, labels], axis = 1, join_axes = [data.index]) \n",
    "    viz2D = pd.concat([data2D, labels], axis = 1, join_axes = [data2D.index])\n",
    "    return clust_out, centers, N, feature_set, data, labels, viz3D, viz2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clust_out, centers, N, strip, data, labels, viz3D, viz2D  = cluster_it_up(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, len(centers)))\n",
    "\n",
    "#2D viz\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "for i,c in enumerate(colors):\n",
    "    single_clus = viz2D.loc[viz2D['label'] == i]\n",
    "    plt.scatter(single_clus[0], single_clus[1], s=3, c = c, label=str(i))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#3D viz\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i,c in enumerate(colors):\n",
    "    single_clus = viz3D.loc[viz3D['label'] == i]\n",
    "    ax.scatter(single_clus[1], single_clus[2], single_clus[0], s=20, c = c, label=str(i))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#scatter matrix\n",
    "#scatter_matrix(data, alpha=0.1, figsize=(6, 6), diagonal='kde')\n",
    "#plt.show()\n",
    "\n",
    "centers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
